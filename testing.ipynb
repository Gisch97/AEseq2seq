{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.seq2seq.dataset import SeqDataset, pad_batch\n",
    "from functools import partial\n",
    "\n",
    "pad_batch_with_fixed_length = partial(pad_batch, fixed_length=128)\n",
    "dataset_path = '/home/gkulemeyer/Documents/Repos/AEseq2seq/data/ArchiveII-KFold/common/fold_0_test.csv'\n",
    "data = SeqDataset( dataset_path, min_len=0, max_len=512, verbose=False, cache_path=None, for_prediction=False,  training=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[32, 33, 33, 33, 35, 36, 38, 51, 58, 58, 62, 64, 65, 65, 66, 70, 71, 71, 72, 72, 72, 72, 72, 72, 73, 73, 73, 73, 74, 74, 74, 74, 74, 74, 74, 74, 75, 75, 75, 75, 75, 75, 75, 75, 75, 75, 75, 75, 75, 76, 76, 76, 76, 76, 76, 76, 76, 76, 76, 76, 76, 76, 76, 76, 76, 76, 76, 76, 76, 76, 76, 76, 76, 76, 76, 76, 76, 76, 76, 76, 76, 76, 76, 76, 76, 76, 77, 77, 77, 77, 77, 77, 77, 77, 77, 77, 77, 77, 77, 77, 77, 77, 77, 77, 77, 77, 77, 77, 77, 77, 77, 77, 77, 77, 77, 77, 77, 78, 78, 78, 78, 78, 78, 79, 79, 80, 81, 82, 82, 82, 84, 85, 85, 85, 85, 85, 86, 86, 86, 87, 87, 87, 88, 88, 88, 88, 89, 89, 90, 90, 90, 90, 91, 91, 91, 91, 92, 92, 92, 92, 93, 94, 96, 96, 96, 98, 98, 98, 98, 98, 98, 98, 98, 98, 99, 99, 99, 100, 100, 100, 101, 101, 101, 101, 101, 101, 101, 101, 102, 102, 102, 103, 103, 103, 103, 103, 103, 103, 103, 103, 103, 104, 104, 104, 105, 105, 105, 105, 106, 106, 106, 106, 107, 107, 107, 108, 108, 110, 110, 111, 111, 111, 111, 111, 112, 113, 113, 113, 114, 114, 114, 114, 115, 115, 115, 115, 115, 115, 115, 116, 116, 116, 116, 116, 116, 116, 116, 116, 116, 116, 116, 116, 116, 116, 116, 116, 116, 116, 116, 116, 116, 116, 117, 117, 117, 117, 117, 117, 117, 117, 117, 117, 117, 117, 117, 117, 117, 117, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 118, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 120, 120, 120, 120, 120, 120, 120, 120, 120, 120, 120, 120, 120, 120, 120, 120, 120, 120, 120, 120, 120, 120, 120, 120, 120, 120, 120, 120, 120, 120, 120, 120, 120, 120, 120, 120, 120, 120, 120, 120, 120, 120, 120, 120, 120, 120, 120, 120, 120, 120, 120, 120, 120, 120, 120, 120, 120, 120, 120, 120, 120, 120, 120, 120, 120, 120, 120, 120, 120, 120, 120, 120, 120, 120, 120, 120, 121, 121, 121, 121, 121, 121, 121, 121, 121, 121, 121, 121, 121, 121, 121, 121, 121, 121, 122, 122, 122, 122, 122, 122, 123, 123, 123, 123, 123, 124, 124, 124, 125, 125, 126, 126, 127]\n"
     ]
    }
   ],
   "source": [
    "L = [data[i]['length'] for i in range(len(data))]\n",
    "L.sort()\n",
    "print(L)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "119\n",
      "torch.Size([4, 119])\n",
      "1\n",
      "120\n",
      "torch.Size([4, 120])\n",
      "2\n",
      "120\n",
      "torch.Size([4, 120])\n"
     ]
    }
   ],
   "source": [
    "for n in range(3):\n",
    "    print(n)\n",
    "    print(data[n]['length'])\n",
    "    print(data[n]['embedding'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 4, 128])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "loader = DataLoader(data, batch_size=1, shuffle=False,collate_fn=pad_batch_with_fixed_length)\n",
    "\n",
    "next(iter(loader))['embedding'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 4, 8])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch as tr\n",
    "x = tr.tensor([[\n",
    "    [1,0,0,0,1,0,0,0],\n",
    "    [0,1,0,0,0,1,0,0],\n",
    "    [0,0,1,0,0,0,1,0],\n",
    "    [0,0,0,1,0,0,0,1],]\n",
    "])\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from torch.utils.data import Dataset\n",
    "import torch as tr\n",
    "import os\n",
    "import json\n",
    "import pickle\n",
    "import random\n",
    "from src.seq2seq.embeddings import OneHotEmbedding\n",
    "\n",
    "\n",
    "class SeqDataset2(Dataset):\n",
    "    def __init__(\n",
    "        self,\n",
    "        dataset_path,\n",
    "        min_len=0,\n",
    "        max_len=512,\n",
    "        verbose=False,\n",
    "        cache_path=None,\n",
    "        for_prediction=False,\n",
    "        training=False,\n",
    "        n_swaps=0,\n",
    "        **kargs,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        interaction_prior: none, probmat\n",
    "        \"\"\"\n",
    "        self.max_len = max_len\n",
    "        self.verbose = verbose\n",
    "        if cache_path is not None and not os.path.isdir(cache_path):\n",
    "            os.mkdir(cache_path)\n",
    "        self.cache = cache_path\n",
    "\n",
    "        # Loading dataset\n",
    "        data = pd.read_csv(dataset_path)\n",
    "        self.training = training\n",
    "\n",
    "        assert (\n",
    "            \"sequence\" in data.columns and \"id\" in data.columns\n",
    "        ), \"Dataset should contain 'id' and 'sequence' columns\"\n",
    "\n",
    "        data[\"len\"] = data.sequence.str.len()\n",
    "\n",
    "        if max_len is None:\n",
    "            max_len = max(data.len)\n",
    "        self.max_len = max_len\n",
    "\n",
    "        datalen = len(data)\n",
    "\n",
    "        data = data[(data.len >= min_len) & (data.len <= max_len)]\n",
    "\n",
    "        if len(data) < datalen:\n",
    "            print(\n",
    "                f\"From {datalen} sequences, filtering {min_len} < len < {max_len} we have {len(data)} sequences\"\n",
    "            )\n",
    "\n",
    "        self.sequences = data.sequence.tolist()\n",
    "        self.ids = data.id.tolist()\n",
    "        self.embedding = OneHotEmbedding()\n",
    "        self.embedding_size = self.embedding.emb_size\n",
    "        self.n_swaps = n_swaps\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.sequences)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        seqid = self.ids[idx]\n",
    "        cache = f\"{self.cache}/{seqid}.pk\"\n",
    "        if (self.cache is not None) and os.path.isfile(cache):\n",
    "            item = pickle.load(open(cache, \"rb\"))\n",
    "        else:\n",
    "            sequence = self.sequences[idx]\n",
    "            L = len(sequence)\n",
    "            seq_emb = self.embedding.seq2emb(sequence)\n",
    "            embedding_with_noise = add_noise(seq_emb, self.n_swaps)\n",
    "\n",
    "            item = {\n",
    "                \"id\": seqid,\n",
    "                \"length\": L,\n",
    "                \"sequence\": sequence,\n",
    "                \"embedding\": seq_emb,\n",
    "                \"embedding_with_noise\": embedding_with_noise,\n",
    "            }\n",
    "\n",
    "            if self.cache is not None:\n",
    "                pickle.dump(item, open(cache, \"wb\"))\n",
    "\n",
    "        return item\n",
    "\n",
    "\n",
    "def pad_batch(batch, fixed_length=0):\n",
    "    \"\"\"batch is a dictionary with different variables lists\"\"\"\n",
    "    L = [b[\"length\"] for b in batch]\n",
    "    if fixed_length == 0:\n",
    "        fixed_length = max(L)\n",
    "    embedding_pad = tr.zeros((len(batch), batch[0][\"embedding\"].shape[0], fixed_length))\n",
    "    embedding_pad_w_noise = tr.zeros(\n",
    "        (len(batch), batch[0][\"embedding_with_noise\"].shape[0], fixed_length)\n",
    "    )\n",
    "    mask = tr.zeros((len(batch), fixed_length), dtype=tr.bool)\n",
    "\n",
    "    for k in range(len(batch)):\n",
    "        embedding_pad[k, :, : L[k]] = batch[k][\"embedding\"]\n",
    "        embedding_pad_w_noise[k, :, : L[k]] = batch[k][\"embedding_with_noise\"]\n",
    "        mask[k, : L[k]] = 1\n",
    "\n",
    "    out_batch = {\n",
    "        \"id\": [b[\"id\"] for b in batch],\n",
    "        \"length\": L,\n",
    "        \"sequence\": [b[\"sequence\"] for b in batch],\n",
    "        \"embedding\": embedding_pad,\n",
    "        \"embedding_with_noise\": embedding_pad_w_noise,\n",
    "        \"mask\": mask,\n",
    "    }\n",
    "\n",
    "    return out_batch\n",
    "\n",
    "\n",
    "def add_noise(x, N=0):\n",
    "    assert N < x.shape[-1], \"N should be lower than the shape of x (starting on 0)\"\n",
    "\n",
    "    if N == 0:\n",
    "        return x\n",
    "\n",
    "    x_l = [_ for _ in range(x.shape[-1])]\n",
    "    random.shuffle(x_l)\n",
    "    v = [0, 1, 2, 3]\n",
    "\n",
    "    for _ in range(N):\n",
    "        pos = x_l[-1]\n",
    "        x_l.pop()\n",
    "        random.shuffle(v)\n",
    "        nt = tr.zeros([4], dtype=tr.float)\n",
    "        nt[v[0]] = 1.0\n",
    "        x[:, pos] = nt\n",
    "    return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "pad_batch_with_fixed_length = partial(pad_batch, fixed_length=128)\n",
    "dataset_path = '/home/gkulemeyer/Documents/Repos/AEseq2seq/data/ArchiveII-KFold/common/fold_0_train.csv'\n",
    "data2 = SeqDataset2( dataset_path, min_len=0, max_len=512, verbose=False, cache_path=None, for_prediction=False,  training=False, n_swaps=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 119])\n",
      "torch.Size([1, 4, 128])\n",
      "torch.Size([4, 119])\n",
      "torch.Size([1, 4, 128])\n"
     ]
    }
   ],
   "source": [
    "print(data2[0]['embedding_with_noise'].shape)\n",
    "\n",
    "loader = DataLoader(data2, batch_size=1, shuffle=False,collate_fn=pad_batch_with_fixed_length) \n",
    "print(next(iter(loader))['embedding_with_noise'].shape)\n",
    "\n",
    "print(data2[0]['embedding'].shape)\n",
    "\n",
    "loader = DataLoader(data2, batch_size=1, shuffle=False,collate_fn=pad_batch_with_fixed_length)\n",
    "print(next(iter(loader))['embedding'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(10.)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abs(next(iter(loader))['embedding_with_noise'].view(-1) - next(iter(loader))['embedding'].view(-1)).sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "seq2seq",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.seq2seq.dataset import SeqDataset, pad_batch\n",
    "from functools import partial\n",
    "\n",
    "pad_batch_with_fixed_length = partial(pad_batch, fixed_length=128)\n",
    "dataset_path = '/home/gkulemeyer/Documents/Repos/AEseq2seq/data/ArchiveII-KFold/common/fold_0_test.csv'\n",
    "data = SeqDataset( dataset_path, min_len=0, max_len=512, verbose=False, cache_path=None, for_prediction=False,  training=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['80,5.8', '81,5.728395061728395', '82,5.658536585365853', '83,5.590361445783133', '84,5.523809523809524', '85,5.458823529411765', '86,5.395348837209302', '87,5.333333333333333', '88,5.2727272727272725', '89,5.213483146067416', '90,5.155555555555556', '91,5.0989010989010985', '92,5.043478260869565', '93,4.989247311827957', '94,4.9361702127659575', '95,4.88421052631579', '96,4.833333333333333', '97,4.783505154639175', '98,4.73469387755102', '99,4.686868686868687', '100,4.64', '101,4.594059405940594', '102,4.549019607843137', '103,4.504854368932039', '104,4.461538461538462', '105,4.419047619047619', '106,4.377358490566038', '107,4.336448598130841', '108,4.296296296296297', '109,4.256880733944954', '110,4.218181818181818', '111,4.18018018018018', '112,4.142857142857143', '113,4.106194690265487', '114,4.0701754385964914', '115,4.034782608695652', '116,4.0', '117,3.965811965811966', '118,3.9322033898305087', '119,3.899159663865546', '120,3.8666666666666667', '121,3.834710743801653', '122,3.80327868852459', '123,3.772357723577236', '124,3.7419354838709675', '125,3.712', '126,3.6825396825396823', '127,3.6535433070866143']\n"
     ]
    }
   ],
   "source": [
    "print([f'{i},{len(data) / i}' for i in range(80,128)]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "119\n",
      "torch.Size([4, 119])\n",
      "1\n",
      "120\n",
      "torch.Size([4, 120])\n",
      "2\n",
      "120\n",
      "torch.Size([4, 120])\n"
     ]
    }
   ],
   "source": [
    "for n in range(3):\n",
    "    print(n)\n",
    "    print(data[n]['length'])\n",
    "    print(data[n]['embedding'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 4, 128])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "loader = DataLoader(data, batch_size=1, shuffle=False,collate_fn=pad_batch_with_fixed_length)\n",
    "\n",
    "next(iter(loader))['embedding'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 4, 8])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch as tr\n",
    "x = tr.tensor([[\n",
    "    [1,0,0,0,1,0,0,0],\n",
    "    [0,1,0,0,0,1,0,0],\n",
    "    [0,0,1,0,0,0,1,0],\n",
    "    [0,0,0,1,0,0,0,1],]\n",
    "])\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from torch.utils.data import Dataset\n",
    "import torch as tr\n",
    "import os\n",
    "import json\n",
    "import pickle\n",
    "import random\n",
    "from src.seq2seq.embeddings import OneHotEmbedding\n",
    "\n",
    "\n",
    "class SeqDataset2(Dataset):\n",
    "    def __init__(\n",
    "        self,\n",
    "        dataset_path,\n",
    "        min_len=0,\n",
    "        max_len=512,\n",
    "        verbose=False,\n",
    "        cache_path=None,\n",
    "        for_prediction=False,\n",
    "        training=False,\n",
    "        n_swaps=0,\n",
    "        **kargs,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        interaction_prior: none, probmat\n",
    "        \"\"\"\n",
    "        self.max_len = max_len\n",
    "        self.verbose = verbose\n",
    "        if cache_path is not None and not os.path.isdir(cache_path):\n",
    "            os.mkdir(cache_path)\n",
    "        self.cache = cache_path\n",
    "\n",
    "        # Loading dataset\n",
    "        data = pd.read_csv(dataset_path)\n",
    "        self.training = training\n",
    "\n",
    "        assert (\n",
    "            \"sequence\" in data.columns and \"id\" in data.columns\n",
    "        ), \"Dataset should contain 'id' and 'sequence' columns\"\n",
    "\n",
    "        data[\"len\"] = data.sequence.str.len()\n",
    "\n",
    "        if max_len is None:\n",
    "            max_len = max(data.len)\n",
    "        self.max_len = max_len\n",
    "\n",
    "        datalen = len(data)\n",
    "\n",
    "        data = data[(data.len >= min_len) & (data.len <= max_len)]\n",
    "\n",
    "        if len(data) < datalen:\n",
    "            print(\n",
    "                f\"From {datalen} sequences, filtering {min_len} < len < {max_len} we have {len(data)} sequences\"\n",
    "            )\n",
    "\n",
    "        self.sequences = data.sequence.tolist()\n",
    "        self.ids = data.id.tolist()\n",
    "        self.embedding = OneHotEmbedding()\n",
    "        self.embedding_size = self.embedding.emb_size\n",
    "        self.n_swaps = n_swaps\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.sequences)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        seqid = self.ids[idx]\n",
    "        cache = f\"{self.cache}/{seqid}.pk\"\n",
    "        if (self.cache is not None) and os.path.isfile(cache):\n",
    "            item = pickle.load(open(cache, \"rb\"))\n",
    "        else:\n",
    "            sequence = self.sequences[idx]\n",
    "            L = len(sequence)\n",
    "            seq_emb = self.embedding.seq2emb(sequence)\n",
    "            embedding_with_noise = add_noise(seq_emb, self.n_swaps)\n",
    "\n",
    "            item = {\n",
    "                \"id\": seqid,\n",
    "                \"length\": L,\n",
    "                \"sequence\": sequence,\n",
    "                \"embedding\": seq_emb,\n",
    "                \"embedding_with_noise\": embedding_with_noise,\n",
    "            }\n",
    "\n",
    "            if self.cache is not None:\n",
    "                pickle.dump(item, open(cache, \"wb\"))\n",
    "\n",
    "        return item\n",
    "\n",
    "\n",
    "def pad_batch(batch, fixed_length=0):\n",
    "    \"\"\"batch is a dictionary with different variables lists\"\"\"\n",
    "    L = [b[\"length\"] for b in batch]\n",
    "    if fixed_length == 0:\n",
    "        fixed_length = max(L)\n",
    "    embedding_pad = tr.zeros((len(batch), batch[0][\"embedding\"].shape[0], fixed_length))\n",
    "    embedding_pad_w_noise = tr.zeros(\n",
    "        (len(batch), batch[0][\"embedding_with_noise\"].shape[0], fixed_length)\n",
    "    )\n",
    "    mask = tr.zeros((len(batch), fixed_length), dtype=tr.bool)\n",
    "\n",
    "    for k in range(len(batch)):\n",
    "        embedding_pad[k, :, : L[k]] = batch[k][\"embedding\"]\n",
    "        embedding_pad_w_noise[k, :, : L[k]] = batch[k][\"embedding_with_noise\"]\n",
    "        mask[k, : L[k]] = 1\n",
    "\n",
    "    out_batch = {\n",
    "        \"id\": [b[\"id\"] for b in batch],\n",
    "        \"length\": L,\n",
    "        \"sequence\": [b[\"sequence\"] for b in batch],\n",
    "        \"embedding\": embedding_pad,\n",
    "        \"embedding_with_noise\": embedding_pad_w_noise,\n",
    "        \"mask\": mask,\n",
    "    }\n",
    "\n",
    "    return out_batch\n",
    "\n",
    "\n",
    "def add_noise(x, N=0):\n",
    "    assert N < x.shape[-1], \"N should be lower than the shape of x (starting on 0)\"\n",
    "\n",
    "    if N == 0:\n",
    "        return x\n",
    "\n",
    "    x_l = [_ for _ in range(x.shape[-1])]\n",
    "    random.shuffle(x_l)\n",
    "    v = [0, 1, 2, 3]\n",
    "\n",
    "    for _ in range(N):\n",
    "        pos = x_l[-1]\n",
    "        x_l.pop()\n",
    "        random.shuffle(v)\n",
    "        nt = tr.zeros([4], dtype=tr.float)\n",
    "        nt[v[0]] = 1.0\n",
    "        x[:, pos] = nt\n",
    "    return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "pad_batch_with_fixed_length = partial(pad_batch, fixed_length=128)\n",
    "dataset_path = '/home/gkulemeyer/Documents/Repos/AEseq2seq/data/ArchiveII-KFold/common/fold_0_train.csv'\n",
    "data2 = SeqDataset2( dataset_path, min_len=0, max_len=512, verbose=False, cache_path=None, for_prediction=False,  training=False, n_swaps=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 119])\n",
      "torch.Size([1, 4, 128])\n",
      "torch.Size([4, 119])\n",
      "torch.Size([1, 4, 128])\n"
     ]
    }
   ],
   "source": [
    "print(data2[0]['embedding_with_noise'].shape)\n",
    "\n",
    "loader = DataLoader(data2, batch_size=1, shuffle=False,collate_fn=pad_batch_with_fixed_length) \n",
    "print(next(iter(loader))['embedding_with_noise'].shape)\n",
    "\n",
    "print(data2[0]['embedding'].shape)\n",
    "\n",
    "loader = DataLoader(data2, batch_size=1, shuffle=False,collate_fn=pad_batch_with_fixed_length)\n",
    "print(next(iter(loader))['embedding'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(10.)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abs(next(iter(loader))['embedding_with_noise'].view(-1) - next(iter(loader))['embedding'].view(-1)).sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "seq2seq",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
